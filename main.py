{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73290,"databundleVersionId":8710574,"sourceType":"competition"},{"sourceId":8622418,"sourceType":"datasetVersion","datasetId":5161626}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aski1140/autoencoders-and-deep-learning-academic-success?scriptVersionId=185239076\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nfrom IPython.display import HTML\nimport random\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set_style(\"dark\")\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-24T13:13:39.196339Z","iopub.execute_input":"2024-06-24T13:13:39.197117Z","iopub.status.idle":"2024-06-24T13:13:52.01406Z","shell.execute_reply.started":"2024-06-24T13:13:39.197086Z","shell.execute_reply":"2024-06-24T13:13:52.013119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color: #E2CECA; font-family: Times New Roman; color: black; font-size: 140%; text-align: center; border-radius: 20px 20px; padding: 15px;\"><strong>About Dataset</strong></p>\n","metadata":{}},{"cell_type":"markdown","source":"**For what purpose was the dataset created?**\n\n    The dataset was created in a project that aims to contribute to the reduction of academic dropout and failure in higher education, by using machine learning techniques to identify students at risk at an early stage of their academic path, so that strategies to support them can be put into place. \n\n    The dataset includes information known at the time of student enrollment â€“ academic path, demographics, and social-economic factors. \n\n    The problem is formulated as a three category classification task (dropout, enrolled, and graduate) at the end of the normal duration of the course. \n    \n    \n**What do the instances in this dataset represent?**\n\n    Each instance is a student","metadata":{}},{"cell_type":"code","source":"df_description = pd.read_excel(\"/kaggle/input/dataset-decription-to-academic-success-season4-6/Dataset_Description.xlsx\",\n                              header = 0)\nHTML(df_description.to_html())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:13:52.016332Z","iopub.execute_input":"2024-06-24T13:13:52.017066Z","iopub.status.idle":"2024-06-24T13:13:52.312583Z","shell.execute_reply.started":"2024-06-24T13:13:52.017029Z","shell.execute_reply":"2024-06-24T13:13:52.311609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The goal of this competition is to predict academic risk of students in higher education. I am gonna try to predict Target feature which can be dropout, enrolled and graduate**","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color: #986156; font-family: Times New Roman; color: white; font-size: 130%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>CONFIGURATION</strong></p>","metadata":{}},{"cell_type":"code","source":"class config:\n    dir_train = \"/kaggle/input/playground-series-s4e6/train.csv\"\n    dir_test = \"/kaggle/input/playground-series-s4e6/test.csv\"\n    dir_sub = \"/kaggle/input/playground-series-s4e6/sample_submission.csv\"\n    \n    n_splits = 5","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:13:52.314128Z","iopub.execute_input":"2024-06-24T13:13:52.314781Z","iopub.status.idle":"2024-06-24T13:13:52.320243Z","shell.execute_reply.started":"2024-06-24T13:13:52.314742Z","shell.execute_reply":"2024-06-24T13:13:52.319208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color: #53B4E7; font-family: Times New Roman; color: white; font-size: 130%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong> Import Datasets and Basic Eda</strong></p>","metadata":{}},{"cell_type":"code","source":"# Import train, test and submission datasets\ndf_train = pd.read_csv(config.dir_train)\ndf_test = pd.read_csv(config.dir_test)\ndf_sub = pd.read_csv(config.dir_sub)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:13:52.321267Z","iopub.execute_input":"2024-06-24T13:13:52.322154Z","iopub.status.idle":"2024-06-24T13:13:52.929238Z","shell.execute_reply.started":"2024-06-24T13:13:52.322122Z","shell.execute_reply":"2024-06-24T13:13:52.92835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Display head of train dataset\nprint(f\"Head of Train Dataset \\n\")\ndf_train.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:13:52.9318Z","iopub.execute_input":"2024-06-24T13:13:52.932108Z","iopub.status.idle":"2024-06-24T13:13:52.960833Z","shell.execute_reply.started":"2024-06-24T13:13:52.932081Z","shell.execute_reply":"2024-06-24T13:13:52.960008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Display head of train dataset\nprint(f\"Head of Test Dataset \\n\")\ndf_test.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:13:52.962151Z","iopub.execute_input":"2024-06-24T13:13:52.962768Z","iopub.status.idle":"2024-06-24T13:13:52.984234Z","shell.execute_reply.started":"2024-06-24T13:13:52.962729Z","shell.execute_reply":"2024-06-24T13:13:52.983259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe().T","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:13:52.985306Z","iopub.execute_input":"2024-06-24T13:13:52.985618Z","iopub.status.idle":"2024-06-24T13:13:53.141206Z","shell.execute_reply.started":"2024-06-24T13:13:52.985587Z","shell.execute_reply":"2024-06-24T13:13:53.140225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:13:53.142375Z","iopub.execute_input":"2024-06-24T13:13:53.142795Z","iopub.status.idle":"2024-06-24T13:13:53.171116Z","shell.execute_reply.started":"2024-06-24T13:13:53.142749Z","shell.execute_reply":"2024-06-24T13:13:53.17024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <p style=\"background-color: #9ADDA0; font-family: Times New Roman; color: white; font-size: 130%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong> Comparison of Test and Train Dataset</strong></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: Times New Roman; color: black; font-size: 100%; text-align: left; border-radius: 15px 15px; padding: 15px;\"> For the test set to be representative of the training set, the data set distributions must be similar. I will check this here</p>","metadata":{}},{"cell_type":"code","source":"def plot_pie(\n            dataframe: pd.DataFrame,\n            list_features: list,\n            title: str,\n            nrows : int = 2,\n            ncols : int = 5\n):\n    \"\"\"\n        This function plots pie graph for features\n\n    \"\"\"\n    #Create figure and axes for plot graph\n    fig, ax = plt.subplots(nrows = nrows, ncols = ncols, figsize = (ncols * 4, nrows*4))\n    \n    #Flatten axes\n    ax = ax.flatten()\n    \n    for idx, column in enumerate(list_features):\n        \n        #Get value counts of feature\n        value_count_feature = dataframe[column].value_counts()\n        #Plot pie graph\n        ax[idx].pie(value_count_feature.values, \n                    labels = value_count_feature.index,\n                    startangle = 140,\n                    autopct='%1.1f%%')\n        #Set title for axis\n        ax[idx].set_title(f\"{column} Pie Chart\")\n        ax[idx].legend()\n    \n    \n    #Remove empty slots\n    for i in range(len(list_features), nrows * ncols):\n        fig.delaxes(ax[i])\n\n    #Set title for figure\n    fig.suptitle(f\"Categorical variables proportion for {title} Set\",\n                fontsize = 16,\n                fontweight = \"bold\",\n                y = 0.95)\n    #Display pie graph\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:13:53.172111Z","iopub.execute_input":"2024-06-24T13:13:53.172381Z","iopub.status.idle":"2024-06-24T13:13:53.182723Z","shell.execute_reply.started":"2024-06-24T13:13:53.172356Z","shell.execute_reply":"2024-06-24T13:13:53.181735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Comparison categorical features proportion between train to test set\ncat_features = [\n        \"Marital status\",\n        #\"Application mode\",\n        #\"Application order\",\n        #\"Course\",\n        \"Daytime/evening attendance\",\n        #\"Previous qualification\",\n        #\"Nacionality\",\n        #\"Mother's qualification\",\n        #\"Father's qualification\",\n        #\"Mother's occupation\",\n        #\"Father's occupation\",\n        \"Displaced\",\n        \"Educational special needs\",\n        \"Debtor\",\n        \"Tuition fees up to date\",\n        \"Gender\",\n        \"Scholarship holder\",\n        \"International\"\n]\n\n#Plot pie graph for categorical variables in train set\nplot_pie(dataframe = df_train,\n        list_features = cat_features,\n        title = \"TRAIN\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:13:53.184346Z","iopub.execute_input":"2024-06-24T13:13:53.18499Z","iopub.status.idle":"2024-06-24T13:13:54.433674Z","shell.execute_reply.started":"2024-06-24T13:13:53.184938Z","shell.execute_reply":"2024-06-24T13:13:54.432767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot pie graph for categorical variables in test set\nplot_pie(dataframe = df_test,\n        list_features = cat_features,\n        title = \"TEST\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:13:54.434763Z","iopub.execute_input":"2024-06-24T13:13:54.435118Z","iopub.status.idle":"2024-06-24T13:13:55.701855Z","shell.execute_reply.started":"2024-06-24T13:13:54.435085Z","shell.execute_reply":"2024-06-24T13:13:55.700972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: Times New Roman; color: black; font-size: 130%; text-align: left; border-radius: 15px 15px; padding: 15px;\"> In terms of categorical variables, Test set and Train set has similar proportion. So test set can represent train set </p>","metadata":{}},{"cell_type":"code","source":"def plot_kdeplot(\n            dataframe_list: [pd.DataFrame, pd.DataFrame],\n            list_features: list,\n            nrows: int = 3,\n            ncols: int = 6\n):\n    \n    \"\"\"\n        This function plot probability distributions for numerical features in Train and Test set to compare them.\n        I just want to learn if this sets same distributions for nuemrical variables\n    \n    \"\"\"\n    #Create figure and axes for lineplot \n    fig, ax = plt.subplots(nrows = nrows, ncols = ncols, figsize = (ncols * 6, nrows * 6))\n    #Flatten axes\n    ax = ax.flatten()\n    \n    for idx, feature in enumerate(list_features):\n        #Plot kdeplot\n        sns.kdeplot(dataframe_list[0][feature], ax = ax[idx], color = \"green\", label = \"Train\")\n        sns.kdeplot(dataframe_list[1][feature], ax = ax[idx], color = \"orange\", label = \"Test\")\n        #Set title for axis\n        #ax[idx].set_title(f\"{feature}\")\n        #Display title\n        ax[idx].legend()\n    \n    #Set title for figure\n    fig.suptitle(f\"Comparison of Probability Disributions for TRAIN and TEST Set\",\n                fontsize = 16,\n                fontweight = \"bold\",\n                y = 0.95)\n    #Display kdeplot \n    plt.show()\n        ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:13:55.703084Z","iopub.execute_input":"2024-06-24T13:13:55.703428Z","iopub.status.idle":"2024-06-24T13:13:55.712657Z","shell.execute_reply.started":"2024-06-24T13:13:55.703395Z","shell.execute_reply":"2024-06-24T13:13:55.711727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_features= [\n        \"Previous qualification (grade)\",\n        \"Admission grade\",\n        \"Age at enrollment\",\n        \"Curricular units 1st sem (credited)\",\n        \"Curricular units 1st sem (enrolled)\",\n        \"Curricular units 1st sem (evaluations)\",\n        \"Curricular units 1st sem (approved)\",\n        \"Curricular units 1st sem (grade)\",\n        \"Curricular units 1st sem (without evaluations)\",\n        \"Curricular units 2nd sem (credited)\",\n        \"Curricular units 2nd sem (enrolled)\",\n        \"Curricular units 2nd sem (evaluations)\",\n        \"Curricular units 2nd sem (approved)\",\n        \"Curricular units 2nd sem (grade)\",\n        \"Curricular units 2nd sem (without evaluations)\", \n        \"Unemployment rate\",\n        \"Inflation rate\", \n        \"GDP\"\n]\n#Plot probabality distributions for numerical variables in train and test set to compare \nplot_kdeplot(dataframe_list = [df_train, df_test],\n            list_features = numerical_features\n            )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:13:55.713774Z","iopub.execute_input":"2024-06-24T13:13:55.714084Z","iopub.status.idle":"2024-06-24T13:14:12.836836Z","shell.execute_reply.started":"2024-06-24T13:13:55.714059Z","shell.execute_reply":"2024-06-24T13:14:12.835923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: Times New Roman; color: black; font-size: 130%; text-align: left; border-radius: 15px 15px; padding: 15px;\"> In terms of numerical variables, Test and train set have similar probability distributions. So Test set can represent train set</p>","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color: #17333D; font-family: Times New Roman; color: white; font-size: 150%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong> EDA</strong></p>","metadata":{}},{"cell_type":"code","source":"def plot_countplot_categoric(\n                dataframe: pd.DataFrame,\n                list_features: list,\n                nrows: int = 2,\n                ncols: int = 5\n):\n    \"\"\"\n        This function plots countplot for categoric features in each of values of target feature \n    \"\"\"\n    #Create figure and axes\n    fig, ax = plt.subplots(nrows = nrows, ncols = ncols, figsize = (ncols * 6, nrows * 6))\n    #Flatten axes\n    ax = ax.flatten()\n    \n    for idx, feature in enumerate(list_features):\n        #Plot countplot\n        sns.countplot(x = feature, hue = \"Target\", data = dataframe, ax = ax[idx])\n    \n    #Remove empty slots \n    for i in range(len(list_features), nrows * ncols):\n        fig.delaxes(ax[i])\n    \n    #Set general title \n    fig.suptitle(f\"Countplot of Categorical Features in Each Target Values\",\n                fontsize = 16,\n                fontweight = \"bold\",\n                y = 0.95)\n    #Display graph\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:12.842067Z","iopub.execute_input":"2024-06-24T13:14:12.842363Z","iopub.status.idle":"2024-06-24T13:14:12.852038Z","shell.execute_reply.started":"2024-06-24T13:14:12.842336Z","shell.execute_reply":"2024-06-24T13:14:12.850969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features = [\n        \"Marital status\",\n        #\"Application mode\",\n        \"Application order\",\n        #\"Course\",\n        \"Daytime/evening attendance\",\n        #\"Previous qualification\",\n        #\"Nacionality\",\n        #\"Mother's qualification\",\n        #\"Father's qualification\",\n        #\"Mother's occupation\",\n        #\"Father's occupation\",\n        \"Displaced\",\n        \"Educational special needs\",\n        \"Debtor\",\n        \"Tuition fees up to date\",\n        \"Gender\",\n        \"Scholarship holder\",\n        \"International\"\n]\n\nplot_countplot_categoric(dataframe = df_train,\n                        list_features = cat_features)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:12.853687Z","iopub.execute_input":"2024-06-24T13:14:12.854234Z","iopub.status.idle":"2024-06-24T13:14:15.8213Z","shell.execute_reply.started":"2024-06-24T13:14:12.854183Z","shell.execute_reply":"2024-06-24T13:14:15.820266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this graph, I examine some categorcal features countplot to get some intuition.\n- Marital status: Those marital status is single (1) mostly graduated,  Those marital status is married (2) and divorced (4) mostly dropout.\n- Application order: In each application order choices, Majority is graduated and minority is enrolled.\n- Daytime/evening attendance: In most of the evening courses students dropped out, while in most of the daytime courses students passed. The fact that the course was held in the evening had a negative impact on the students.\n- Displaced: In most of the rows with Displaced as no (0), students dropped the course, while in most of the rows with Displaced as yes (1), students graduated.\n- Debtor: Most of the debtor students dropped the course, while most of the non-debtor students graduated.\n- Tuition feed up to date: in courses with tuition fees up to date of 1, the majority of students graduated, while in courses with tuition fees up to date of 0, the majority of students dropped.\n- Gender: While most of the male students dropped, most of the female students passed the course.\n- Scholarship holder: While the majority of scholarship students graduated, the majority of non-scholarship students dropped.","metadata":{}},{"cell_type":"code","source":"def plot_kdeplot_hueTarget(\n            list_features: list,\n            dataframe: pd.DataFrame = df_train\n            \n\n):\n    \"\"\"\n        This function plot probability distributions for the first show_count(parameter) values with hue Target\n    \"\"\"\n    #Create figure and axes\n    fig, ax = plt.subplots(nrows = 6, ncols = 3, figsize = (18, 36))\n    #Flatten axes\n    ax = ax.flatten()\n    \n    for idx, feature in enumerate(list_features):\n        #Plot kdeplot with hue Target\n        sns.kdeplot(data = dataframe, x = feature, hue = \"Target\", ax = ax[idx])\n    #Set general title\n    fig.suptitle(f\"Probability Distributions with Hue as Target\",\n                fontsize = 16,\n                fontweight = \"bold\",\n                y = 0.90)\n    #Display lineplot\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:15.82256Z","iopub.execute_input":"2024-06-24T13:14:15.822862Z","iopub.status.idle":"2024-06-24T13:14:15.829863Z","shell.execute_reply.started":"2024-06-24T13:14:15.822835Z","shell.execute_reply":"2024-06-24T13:14:15.828752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_kdeplot_hueTarget(numerical_features)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:15.830818Z","iopub.execute_input":"2024-06-24T13:14:15.831135Z","iopub.status.idle":"2024-06-24T13:14:33.246578Z","shell.execute_reply.started":"2024-06-24T13:14:15.83111Z","shell.execute_reply":"2024-06-24T13:14:33.245581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am gonna evaluate the features which has differences in terms of probablity distributions\n- Curricular units 2nd sem (grade): It means grade average in the 2nd semester (between 0 and 20). Most studens dropped are clustered around 0, while most students graduated are clustered around 13.\n- Curricular units 2nd sem (approved): It means number of curricular units approved in the 2nd semester. Most studens dropped are clustered around 0\n- Curricular units 2nd sem (evaluations): It means number of evaluations to curricular units in the 2nd semester. Most studens dropped are clustered around 0\n- Curricular units 1st sem (grade): It means grade average in the 1st semester (between 0 and 20). Most studens dropped are clustered around 0, while most students graduated are clustered around 13.\n- Curricular units 1st sem (approved): It means number of curricular units approved in the 1st semester. Most studens dropped are clustered around 0\n- Curricular units 1st sem (evaluations): It means number of evaluations to curricular units in the 1st semester. Most studens dropped are clustered around 0","metadata":{}},{"cell_type":"code","source":"#Create figure\nplt.figure(figsize = (18, 8))\n#Determine correlations\ncorrelations = df_train[numerical_features].corr().abs()\n#Determine mask for heatmap\nmask = np.triu(np.ones_like(correlations, dtype = \"bool\"))\n#Plot heatmap\nsns.heatmap(correlations, annot = True, fmt = \".2f\", cmap = \"Spectral\", mask = mask)\n#Display graph\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:33.247822Z","iopub.execute_input":"2024-06-24T13:14:33.248133Z","iopub.status.idle":"2024-06-24T13:14:34.421204Z","shell.execute_reply.started":"2024-06-24T13:14:33.248105Z","shell.execute_reply":"2024-06-24T13:14:34.420291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to correlations map:\n- Curricular units 1st sem (grade) and Curricular units 1st sem (approved)\n- Curricular units 2nd sem (credited) and Curricular units 1st sem (credited)\n- Curricular units 2nd sem (enrolled) and Curricular units 1st sem (enrolled)\n- Curricular units 2nd sem (evaluations) and Curricular units 1st sem (evaluations)\n- Curricular units 2nd sem (approved) and Curricular units 1st sem (approved)\n- Curricular units 2nd sem (approved) and Curricular units 1st sem (grade)\n- Curricular units 1st sem (approved) and Curricular units 2nd sem (grade)\n- Curricular units 1st sem (grade) and Curricular units 2nd sem (grade)\n- Curricular units 2nd sem (grade) and Curricular units 2nd sem (approved)\n\nhas high correlations. So I will remove features:\n- Curricular units 1st sem (grade)\n- Curricular units 1st sem (credited)\n- Curricular units 1st sem (enrolled)\n- Curricular units 1st sem (evaluations)\n- Curricular units 2nd sem (approved)\n","metadata":{}},{"cell_type":"code","source":"#Determine highly correlated features\nremoved_features = [\n    \"Curricular units 1st sem (grade)\",\n    \"Curricular units 1st sem (credited)\",\n    \"Curricular units 1st sem (enrolled)\",\n    \"Curricular units 1st sem (evaluations)\",\n    \"Curricular units 2nd sem (approved)\"\n    \n]\n#Remove highly correlated features from train and test set\ndf_train = df_train.drop(removed_features, axis = 1)\ndf_test = df_test.drop(removed_features, axis = 1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:34.422374Z","iopub.execute_input":"2024-06-24T13:14:34.42277Z","iopub.status.idle":"2024-06-24T13:14:34.437801Z","shell.execute_reply.started":"2024-06-24T13:14:34.422729Z","shell.execute_reply":"2024-06-24T13:14:34.436883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <p style=\"background-color: #818174; font-family: Times New Roman; color: white; font-size: 130%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>Find Best Distributions for Numerical Variables</strong></p>","metadata":{}},{"cell_type":"code","source":"pip install distfit","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:34.438937Z","iopub.execute_input":"2024-06-24T13:14:34.439324Z","iopub.status.idle":"2024-06-24T13:14:49.160888Z","shell.execute_reply.started":"2024-06-24T13:14:34.439287Z","shell.execute_reply":"2024-06-24T13:14:49.159572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from distfit import distfit ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:49.162449Z","iopub.execute_input":"2024-06-24T13:14:49.162841Z","iopub.status.idle":"2024-06-24T13:14:50.45208Z","shell.execute_reply.started":"2024-06-24T13:14:49.162812Z","shell.execute_reply":"2024-06-24T13:14:50.45104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: Times New Roman; color: black; font-size: 130%; text-align: left; border-radius: 15px 15px; padding: 15px;\">The distfit library can determine the best fit across 89 theoretical distributions which are utilized from the scipy library. To score the fit, there are four goodness-of-fit statistical tests; Residual Sum of Squares (RSS or SSE), Wasserstein, Kolmogorov-Smirnov (KS), and Energy. For each fitted theoretical distribution, the loc, scale, and arg parameters are returned, such as mean and standard deviation for normal distribution. <br><br>And also best practice is to use both statistics and a visual curation to decide what the best distribution fit is. Using the PDF/CDF and QQ plots can be some of the best tools to guide those decisions. These plots will help to visually guide whether a distribution is a good fit. We can see in graphs the PDF with the confidence intervals and the CDF plot. The confidence intervals are automatically set to 95% CII but can be changed using the alpha parameter during initialization. When using the plot functionality, it automatically shows the histogram in bars and with a line, PDF/CDF, and confidence intervals.<br/> <br/></p>\n\n[Source](https://towardsdatascience.com/how-to-find-the-best-theoretical-distribution-for-your-data-a26e5673b4bd)","metadata":{}},{"cell_type":"code","source":"def plot_continuous_distributions(dataframe: pd.DataFrame, \n                                  feature: str,\n                               ):\n    \"\"\"\n        This function finds best distribution for feature we want and plot PDF and CDF\n    \n    \"\"\"\n    \n    \n    #Create figure and axes\n    fig, ax = plt.subplots(1, 3, figsize = (30, 10))\n    #Flatten axes\n    ax = ax.flatten()\n    #Create distribution in popular distributions\n    dfit = distfit(distr = \"popular\", n_boots = 10)\n        \n    #Fit and transform to feature\n    results = dfit.fit_transform(dataframe.loc[~dataframe[feature].isnull(), feature].values)\n    #Create graph to find best distribution\n    dfit.plot_summary(n_top = 10, ax=ax[0])\n    # PDF for only the best fit\n    dfit.plot(chart='PDF', n_top=1, ax=ax[1])\n    # CDF for the top 10 fits\n    dfit.plot(chart='CDF', n_top=10, ax=ax[2])\n    \n    #Set title\n    fig.suptitle(f\"Probability Distribution for {feature}\",\n                fontsize = 16,\n                fontweight = \"bold\",\n                y = 0.95)\n    \n    #Show graph\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:50.453314Z","iopub.execute_input":"2024-06-24T13:14:50.454413Z","iopub.status.idle":"2024-06-24T13:14:50.463905Z","shell.execute_reply.started":"2024-06-24T13:14:50.454381Z","shell.execute_reply":"2024-06-24T13:14:50.462934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot distrutions for Previous qualification (grade)\nplot_continuous_distributions(dataframe = df_train,\n                            feature = \"Previous qualification (grade)\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:14:50.465489Z","iopub.execute_input":"2024-06-24T13:14:50.466167Z","iopub.status.idle":"2024-06-24T13:15:20.166782Z","shell.execute_reply.started":"2024-06-24T13:14:50.466129Z","shell.execute_reply":"2024-06-24T13:15:20.165885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot distrutions for Admission grade\nplot_continuous_distributions(dataframe = df_train,\n                            feature = \"Admission grade\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:15:20.167996Z","iopub.execute_input":"2024-06-24T13:15:20.168287Z","iopub.status.idle":"2024-06-24T13:15:49.045997Z","shell.execute_reply.started":"2024-06-24T13:15:20.168261Z","shell.execute_reply":"2024-06-24T13:15:49.044906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color: #757065; font-family: Times New Roman; color: white; font-size: 130%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>AutoEncoder for Dimensionality Reduction</strong></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: Times New Roman; color: black; font-size: 130%; text-align: left; border-radius: 15px 15px; padding: 15px;\"> I am gonna use Autoencoder to dimensionality reduction. But I dont want to use categorical features in dimensionality reduction. So just I am gonna use other features. Dimension will decrease from 13 to 4. Before dimensionality reduction I am gonna scale the features.  </p>","metadata":{}},{"cell_type":"markdown","source":"## <p style=\"background-color: #42cbf5; font-family: Times New Roman; color: white; font-size: 120%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>Scaled Data with MinMaxScaler</strong></p>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:15:49.047339Z","iopub.execute_input":"2024-06-24T13:15:49.047696Z","iopub.status.idle":"2024-06-24T13:15:49.102395Z","shell.execute_reply.started":"2024-06-24T13:15:49.047662Z","shell.execute_reply":"2024-06-24T13:15:49.101363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_features= [feature for feature in numerical_features if not feature in removed_features]\nprint(\"Features that will decrease in dimension \\n\" + \"\\n\".join(numerical_features))\n\n#Scale data with MinMaxScaler\nminmax_scaler = MinMaxScaler()\ndf_train[numerical_features] = minmax_scaler.fit_transform(df_train[numerical_features])\ndf_test[numerical_features] = minmax_scaler.transform(df_test[numerical_features])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:15:49.105665Z","iopub.execute_input":"2024-06-24T13:15:49.105984Z","iopub.status.idle":"2024-06-24T13:15:49.137227Z","shell.execute_reply.started":"2024-06-24T13:15:49.105936Z","shell.execute_reply":"2024-06-24T13:15:49.136145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <p style=\"background-color: #42cbf5; font-family: Times New Roman; color: white; font-size: 130%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>AutoEncoders</strong></p>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.models import Model, Sequential\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:15:49.138531Z","iopub.execute_input":"2024-06-24T13:15:49.138846Z","iopub.status.idle":"2024-06-24T13:15:49.220543Z","shell.execute_reply.started":"2024-06-24T13:15:49.13881Z","shell.execute_reply":"2024-06-24T13:15:49.219679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Specify early stopping conditions\nes = EarlyStopping(\n    monitor='val_acc', \n    mode='max',\n    patience=30,\n    restore_best_weights = True\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:15:49.221663Z","iopub.execute_input":"2024-06-24T13:15:49.221936Z","iopub.status.idle":"2024-06-24T13:15:49.226434Z","shell.execute_reply.started":"2024-06-24T13:15:49.221912Z","shell.execute_reply":"2024-06-24T13:15:49.225476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determine input dimension\ninput_dim = Input(shape = (len(numerical_features), ))\n\n#This is the dimension of the latent space (encoding space)\nlatent_dim = 4\n\n#Determine x_train for autoencoder model\nX_train = df_train[numerical_features].copy()\n\n#Split the data for validation and train set\nX_train, X_test, y_train, y_test = train_test_split(X_train, df_train[\"Target\"], train_size = 0.80, random_state = 42)\n\nencoded1 =  Dense(512, activation = \"leaky_relu\")(input_dim)\nencoded2 =  Dense(256, activation = \"leaky_relu\")(encoded1)\nencoded3 =  Dense(128, activation = \"leaky_relu\")(encoded2)\nencoded4 =  Dense(64, activation = \"leaky_relu\")(encoded3)\nencoded5 =  Dense(32, activation = \"leaky_relu\")(encoded4)\nencoded6 =  Dense(16, activation = \"leaky_relu\")(encoded5)\nencoded7 =  Dense(8, activation = \"leaky_relu\")(encoded6)\nencoded8 =  Dense(4, activation = \"leaky_relu\")(encoded7)\nencoded9 =  Dense(latent_dim, activation = \"leaky_relu\")(encoded8)\n\ndecoded1 = Dense(4, activation = \"leaky_relu\")(encoded9)\ndecoded2 = Dense(8, activation = \"leaky_relu\")(decoded1)\ndecoded3 = Dense(16, activation = \"leaky_relu\")(decoded2)\ndecoded4 = Dense(32, activation = \"leaky_relu\")(decoded3)\ndecoded5 = Dense(64, activation = \"leaky_relu\")(decoded4)\ndecoded6 = Dense(128, activation = \"leaky_relu\")(decoded5)\ndecoded7 = Dense(256, activation = \"leaky_relu\")(decoded6)\ndecoded8 = Dense(512, activation = \"leaky_relu\")(decoded7)\ndecoded9 = Dense(len(numerical_features), activation = \"sigmoid\")(decoded8)\n\n#Create autoencoder model\nautoencoder = Model(inputs = input_dim, outputs = decoded9)\n#Compile autoencoder model\nautoencoder.compile(loss = \"mse\", \n                    optimizer = \"adam\", \n                    metrics = [\"mae\"]) \n#fit model\nhistory = autoencoder.fit(X_train, X_train, \n                          epochs = 100, \n                          batch_size = 32, verbose = 1, \n                          validation_data = (X_test, X_test), \n                          shuffle = False, \n                          callbacks = [es])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:15:49.227919Z","iopub.execute_input":"2024-06-24T13:15:49.228259Z","iopub.status.idle":"2024-06-24T13:28:40.877119Z","shell.execute_reply.started":"2024-06-24T13:15:49.22823Z","shell.execute_reply":"2024-06-24T13:28:40.875948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_model_performance(history):\n    \"\"\"\n        Plot train loss, accuracy and valdiation loss, accuracy\n    \n    \"\"\"\n    \n    # plot model performance\n    mae = history.history['mae']\n    val_mae = history.history['val_mae']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(1, len(history.epoch) + 1)\n\n    plt.figure(figsize=(15,5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, mae, label=\"Train Set\")\n    plt.plot(epochs_range, val_mae, label=\"Val Set\")\n    plt.legend(loc=\"best\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Mean Absolute Error\")\n    plt.title(\"Model MAE\")\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label=\"Train Set\")\n    plt.plot(epochs_range, val_loss, label=\"Val Set\")\n    plt.legend(loc=\"best\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Model Loss\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:28:40.878665Z","iopub.execute_input":"2024-06-24T13:28:40.879004Z","iopub.status.idle":"2024-06-24T13:28:40.888338Z","shell.execute_reply.started":"2024-06-24T13:28:40.878945Z","shell.execute_reply":"2024-06-24T13:28:40.887309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_performance(history)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:40.889556Z","iopub.execute_input":"2024-06-24T13:28:40.88992Z","iopub.status.idle":"2024-06-24T13:28:41.573161Z","shell.execute_reply.started":"2024-06-24T13:28:40.889883Z","shell.execute_reply":"2024-06-24T13:28:41.571882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reset_index(drop = True)\nX_test = X_test.reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:41.574351Z","iopub.execute_input":"2024-06-24T13:28:41.574716Z","iopub.status.idle":"2024-06-24T13:28:41.58069Z","shell.execute_reply.started":"2024-06-24T13:28:41.574679Z","shell.execute_reply":"2024-06-24T13:28:41.579614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_orig_vs_recon(title=\"\", n_samples=3):\n    \"\"\"\n        This function compare reconstructed data with autoencoder and orginal data in three example\n    \"\"\"\n    #Create figure\n    fig, ax = plt.subplots(nrows = 3, ncols = 1, figsize=(15,15))\n    #Set title\n    fig.suptitle(title, \n                 fontsize = 16,\n                 fontweight = \"bold\",\n                 y = 0.90)\n    for i in range(3):\n        plt.subplot(3, 1, i+1)\n        #Determine random integer value\n        idx = random.sample(range(X_train.shape[0]), 1)\n        #Plot reconstructed data\n        plt.plot(autoencoder.predict(X_train.iloc[idx]).squeeze(), label=\"reconstructed\")\n        #Plot otiginal data\n        plt.plot(X_train.iloc[idx].squeeze(), label= \"original\")\n        #Set x axis names\n        ax[i].set_xticklabels([])\n        #Display title\n        plt.legend()\n       \n    #Display graph\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:28:41.581904Z","iopub.execute_input":"2024-06-24T13:28:41.582259Z","iopub.status.idle":"2024-06-24T13:28:41.592034Z","shell.execute_reply.started":"2024-06-24T13:28:41.582226Z","shell.execute_reply":"2024-06-24T13:28:41.591177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_orig_vs_recon(\"Example of After Reconstructed with AutoEncoder\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:41.593016Z","iopub.execute_input":"2024-06-24T13:28:41.59329Z","iopub.status.idle":"2024-06-24T13:28:43.053975Z","shell.execute_reply.started":"2024-06-24T13:28:41.593266Z","shell.execute_reply":"2024-06-24T13:28:43.053005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create encoder model\nencoder = Model(inputs = input_dim, outputs = encoded9)\nencoded_input = Input(shape = (latent_dim, ))\n\n#Create dataframe to train set\nencoded_train = pd.DataFrame(encoder.predict(df_train[numerical_features]))\nencoded_train = encoded_train.add_prefix(\"feature\")\n\n#Create dataframe to test set\nencoded_test = pd.DataFrame(encoder.predict(df_test[numerical_features]))\nencoded_test = encoded_test.add_prefix(\"feature\")\n\n#Dimensionality reduction to train and test set\ndf_train = df_train.drop(numerical_features, axis = 1)\ndf_train = pd.concat([df_train, encoded_train], axis = 1)\n\ndf_test = df_test.drop(numerical_features, axis = 1)\ndf_test = pd.concat([df_test, encoded_test], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:43.055535Z","iopub.execute_input":"2024-06-24T13:28:43.056219Z","iopub.status.idle":"2024-06-24T13:28:52.101438Z","shell.execute_reply.started":"2024-06-24T13:28:43.05618Z","shell.execute_reply":"2024-06-24T13:28:52.100246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"New Train Set shaoe: {df_train.shape}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:28:52.1029Z","iopub.execute_input":"2024-06-24T13:28:52.103312Z","iopub.status.idle":"2024-06-24T13:28:52.10902Z","shell.execute_reply.started":"2024-06-24T13:28:52.103274Z","shell.execute_reply":"2024-06-24T13:28:52.107939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color: #17333D; font-family: Times New Roman; color: white; font-size: 150%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>MODELING</strong></p>","metadata":{}},{"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:52.11026Z","iopub.execute_input":"2024-06-24T13:28:52.110599Z","iopub.status.idle":"2024-06-24T13:28:52.117583Z","shell.execute_reply.started":"2024-06-24T13:28:52.110559Z","shell.execute_reply":"2024-06-24T13:28:52.116507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_map = {\n        \"Graduate\": 0,\n        \"Dropout\": 1,\n        \"Enrolled\": 2\n           \n}\n\n#Map target feature in train set\ndf_train[\"Target\"] = df_train[\"Target\"].map(dict_map)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:52.118855Z","iopub.execute_input":"2024-06-24T13:28:52.119389Z","iopub.status.idle":"2024-06-24T13:28:52.135614Z","shell.execute_reply.started":"2024-06-24T13:28:52.119354Z","shell.execute_reply":"2024-06-24T13:28:52.134602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set id as a index\ndf_train = df_train.set_index(\"id\")\ndf_test = df_test.set_index(\"id\")\n\n#Specify categoric variables\ncat_features = [\n        \"Marital status\",\n        \"Application mode\",\n        \"Application order\",\n        \"Course\",\n        \"Daytime/evening attendance\",\n        \"Previous qualification\",\n        \"Nacionality\",\n        \"Mother's qualification\",\n        \"Father's qualification\",\n        \"Mother's occupation\",\n        \"Father's occupation\",\n        \"Displaced\",\n        \"Educational special needs\",\n        \"Debtor\",\n        \"Tuition fees up to date\",\n        \"Gender\",\n        \"Scholarship holder\",\n        \"International\"\n]\n\n#Change datatype to category\ndf_train[cat_features] = df_train[cat_features].astype(\"category\")\ndf_test[cat_features] = df_test[cat_features].astype(\"category\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:52.137112Z","iopub.execute_input":"2024-06-24T13:28:52.13803Z","iopub.status.idle":"2024-06-24T13:28:52.206759Z","shell.execute_reply.started":"2024-06-24T13:28:52.137992Z","shell.execute_reply":"2024-06-24T13:28:52.205732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Determine StratifiedKFold\nst_kfold = StratifiedKFold(n_splits = config.n_splits)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:28:52.208064Z","iopub.execute_input":"2024-06-24T13:28:52.208369Z","iopub.status.idle":"2024-06-24T13:28:52.212469Z","shell.execute_reply.started":"2024-06-24T13:28:52.208343Z","shell.execute_reply":"2024-06-24T13:28:52.211588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(\n                X: pd.DataFrame,\n                y: pd.Series,\n                cv: sklearn.model_selection,\n                model\n                \n):\n    #Create empty lists to \n    models = list()\n    val_preds = list()\n    fold_val_acc_scores = list()\n    elapsed_time = 0\n    for idx, (train_idx, val_idx) in enumerate(cv.split(X=X, y = y)):\n        start_time = time.time()\n\n        print(f\"train_idx: {train_idx}\")\n        print(f\"val_idx: {val_idx}\")\n\n        X_train = X.iloc[train_idx].copy()\n        y_train = y.iloc[train_idx].copy()\n        X_val = X.iloc[val_idx].copy()\n        y_val = y.iloc[val_idx].copy()\n\n\n        model.fit(X_train,\n                  y_train,\n                  eval_set=[(X_train, y_train),(X_val, y_val)],\n                  verbose=250)\n\n\n        val_pred = model.predict(X_val)\n        val_preds.append(val_pred)\n\n        fold_val_acc_score = accuracy_score(y_true = y_val, y_pred = val_pred)\n        print(f\"\\nFold {idx + 1} Accuracy Score for Val Set:{fold_val_acc_score}\")\n\n\n        fold_val_acc_scores.append(fold_val_acc_score)\n\n        #model_file_path = f\"{name}_fold_{idx + 1}.pkl\"\n        #joblib.dump(model, os.path.join(config.model_path, model_file_path))\n        models.append(model)\n\n        end_time = time.time()\n        elapsed = end_time - start_time\n        print(f\"Time to Model for Fold {idx + 1}: {elapsed}\")\n        print(\"*\"*120)\n\n        elapsed_time += elapsed\n\n    print(f\"model run time is : {elapsed_time} seconds\")\n    print(f\"model has a mean of Accuracy Score for Val Set: {np.mean(fold_val_acc_scores)}\")\n    print(\"*\"*120)\n\n\n    return fold_val_acc_scores, models, val_preds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:28:52.220298Z","iopub.execute_input":"2024-06-24T13:28:52.220587Z","iopub.status.idle":"2024-06-24T13:28:52.231201Z","shell.execute_reply.started":"2024-06-24T13:28:52.220561Z","shell.execute_reply":"2024-06-24T13:28:52.230357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.drop(\"Target\", axis = 1).copy()\ny_train = df_train[\"Target\"].copy()\nX_test = df_test.copy()\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:28:52.232386Z","iopub.execute_input":"2024-06-24T13:28:52.232772Z","iopub.status.idle":"2024-06-24T13:28:52.24523Z","shell.execute_reply.started":"2024-06-24T13:28:52.232728Z","shell.execute_reply":"2024-06-24T13:28:52.244311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <p style=\"background-color: #f5b342; font-family: Times New Roman; color: white; font-size: 130%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>XGBOOST</strong></p>","metadata":{}},{"cell_type":"code","source":"pip install xgboost","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-24T13:28:52.246329Z","iopub.execute_input":"2024-06-24T13:28:52.246594Z","iopub.status.idle":"2024-06-24T13:29:04.608598Z","shell.execute_reply.started":"2024-06-24T13:28:52.246571Z","shell.execute_reply":"2024-06-24T13:29:04.607366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:29:04.610396Z","iopub.execute_input":"2024-06-24T13:29:04.610766Z","iopub.status.idle":"2024-06-24T13:29:04.773201Z","shell.execute_reply.started":"2024-06-24T13:29:04.61073Z","shell.execute_reply":"2024-06-24T13:29:04.772132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_XGB = {\n    \"booster\": \"gbtree\",\n    #\"device\": \"gpu\", #if you want to use gpu\n    \"max_depth\": 2,\n    \"lambda\": 1, #L2 regularization\n    \"tree_method\": \"hist\", #Faster histogram optimized approximate greedy algorithm.\n    \"grow_policy\": \"depthwise\", #Controls a way new nodes are added to the tree.\n    \"enable_categorical\": True,\n    \"objective\": \"multi:softmax\",\n    \"eval_metric\": \"merror\", #(wrong cases)/(all cases)\n    \"learning_rate\": 0.01,\n    \"early_stopping_rounds\" : 500,\n    \"seed\": 42,\n    \"n_estimators\":5000 \n    \n}\n\nmodel = XGBClassifier(**params_XGB)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:29:04.775456Z","iopub.execute_input":"2024-06-24T13:29:04.77585Z","iopub.status.idle":"2024-06-24T13:29:04.78232Z","shell.execute_reply.started":"2024-06-24T13:29:04.775798Z","shell.execute_reply":"2024-06-24T13:29:04.78116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_val_acc_scores_xgboost, models_xgb, val_preds_xgb = create_model(X = X_train,\n                                                                     y = y_train,\n                                                                     cv = st_kfold,\n                                                                     model = model)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:29:04.783845Z","iopub.execute_input":"2024-06-24T13:29:04.784204Z","iopub.status.idle":"2024-06-24T13:38:33.241723Z","shell.execute_reply.started":"2024-06-24T13:29:04.784172Z","shell.execute_reply":"2024-06-24T13:38:33.240892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <p style=\"background-color: #f5b342; font-family: Times New Roman; color: white; font-size: 130%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>Deep Learning</strong></p>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom tensorflow.keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:38:33.242988Z","iopub.execute_input":"2024-06-24T13:38:33.243785Z","iopub.status.idle":"2024-06-24T13:38:33.250255Z","shell.execute_reply.started":"2024-06-24T13:38:33.243752Z","shell.execute_reply":"2024-06-24T13:38:33.249582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create one hot encoder\none_hot_encoder = OneHotEncoder(sparse_output = False, handle_unknown = \"ignore\")\n\n#One hot encoder to train set\nresults_train = one_hot_encoder.fit_transform(X_train[cat_features])\nX_train = pd.concat([X_train, pd.DataFrame(results_train, index = X_train.index)], axis = 1)\nX_train = X_train.drop(cat_features, axis = 1)\n\n#One hot encoder to test set\nresults_test = one_hot_encoder.transform(X_test[cat_features])\nX_test = pd.concat([X_test, pd.DataFrame(results_test, index = X_test.index)], axis = 1)\nX_test = X_test.drop(cat_features, axis = 1)\n\nprint(f\"X_train shape after One Hot Encoder: {X_train.shape}\")\nprint(f\"X_test shape after One Hot Encoder: {X_test.shape}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:38:33.252672Z","iopub.execute_input":"2024-06-24T13:38:33.253282Z","iopub.status.idle":"2024-06-24T13:38:34.239018Z","shell.execute_reply.started":"2024-06-24T13:38:33.253254Z","shell.execute_reply":"2024-06-24T13:38:34.237983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create early stopping conditions for MLP model\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10, restore_best_weights=True, start_from_epoch = 10)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:38:34.240434Z","iopub.execute_input":"2024-06-24T13:38:34.241163Z","iopub.status.idle":"2024-06-24T13:38:34.246378Z","shell.execute_reply.started":"2024-06-24T13:38:34.241106Z","shell.execute_reply":"2024-06-24T13:38:34.245389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build deep learning model to classification\nmodel = Sequential([\n        Dense(64, activation = \"leaky_relu\", kernel_regularizer = l2(0.001), input_shape = (X_train.shape[1], )),\n        Dense(32, activation = \"leaky_relu\", kernel_regularizer = l2(0.001)),\n        Dense(16, activation = \"leaky_relu\", kernel_regularizer = l2(0.001)),\n        Dense(3, activation = \"softmax\")\n        \n])\n#Display sumamry of model\nmodel.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:38:34.247532Z","iopub.execute_input":"2024-06-24T13:38:34.247848Z","iopub.status.idle":"2024-06-24T13:38:34.307171Z","shell.execute_reply.started":"2024-06-24T13:38:34.247823Z","shell.execute_reply":"2024-06-24T13:38:34.3063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_FCL_model(\n                X:pd.DataFrame,\n                y: pd.Series,\n                cv:sklearn.model_selection,\n                model: tf.keras.models,\n                early_stopping: tf.keras.callbacks.EarlyStopping\n):\n    \n    models = list()\n    val_preds = list()\n    fold_val_acc_scores = list()\n    elapsed_time = 0\n    histories = list()\n    \n    for idx, (train_idx, val_idx) in enumerate(cv.split(X = X, y = y)):\n        start_time = time.time()\n        \n        X_train = np.array(X.iloc[train_idx].values.copy())\n        y_train = np.array(y.iloc[train_idx].values.copy())\n        \n        X_val = np.array(X.iloc[val_idx].values.copy())\n        y_val = np.array(y.iloc[val_idx].values.copy())\n        \n       \n        model.compile(\n            optimizer = \"adam\",\n            loss = \"sparse_categorical_crossentropy\",\n            metrics = [\"acc\"]\n            \n        )\n        \n        history = model.fit(X_train, \n                            y_train, \n                            epochs = 50, \n                            batch_size = 32, \n                            validation_data = (X_val, y_val), \n                            callbacks = [early_stopping], \n                            verbose = 2\n                           )\n        \n        #Add history to list\n        histories.append(history)\n        #Predict val set\n        val_pred = np.argmax(model.predict(X_val), axis = 1)   \n        #Append predictions to list\n        val_preds.append(val_pred)\n        #Compute accuracy score for val set\n        fold_val_acc_score = accuracy_score(y_true = y_val, y_pred = val_pred)\n        print(f\"\\nFeed Forward Neural Network Model Fold {idx + 1} Accuracy Score for Val Set:{fold_val_acc_score}\")\n        #Append Accuracy score to list\n        fold_val_acc_scores.append(fold_val_acc_score)\n\n        #model_file_path = f\"{name}_fold_{idx + 1}.pkl\"\n        #joblib.dump(model, os.path.join(config.model_path, model_file_path))\n        models.append(model)\n\n        end_time = time.time()\n        elapsed = end_time - start_time\n        print(f\"Time to Feed Forward Neural Network Model for Fold {idx + 1}: {elapsed}\")\n        print(\"*\"*120)\n\n        elapsed_time += elapsed\n        \n    print(f\"Feed Forward Neural Network Model run time is : {elapsed_time} seconds\")\n    print(f\"Feed Forward Neural Network Model has a mean of Accuracy Score for Val Set: {np.mean(fold_val_acc_scores)}\")\n    print(\"*\"*120)\n\n    #mean_squared_error_scores.append(fold_test_mse_scores)\n\n    return fold_val_acc_scores, models, histories, val_preds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:38:34.308348Z","iopub.execute_input":"2024-06-24T13:38:34.308682Z","iopub.status.idle":"2024-06-24T13:38:34.321167Z","shell.execute_reply.started":"2024-06-24T13:38:34.308651Z","shell.execute_reply":"2024-06-24T13:38:34.320287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_val_acc_scores_feed, models_feed, histories_feed, val_preds_feed = create_FCL_model(X_train,\n                                                                                        y_train,\n                                                                                        cv = st_kfold,\n                                                                                        model = model,\n                                                                                        early_stopping = early_stopping)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:38:34.322365Z","iopub.execute_input":"2024-06-24T13:38:34.32264Z","iopub.status.idle":"2024-06-24T13:47:02.389292Z","shell.execute_reply.started":"2024-06-24T13:38:34.322616Z","shell.execute_reply":"2024-06-24T13:47:02.388353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows = 1, ncols = config.n_splits, figsize = (25, 6))\nfor i, history in enumerate(histories_feed):\n    #Lineplot for train and validation loss\n    sns.lineplot(history.history[\"loss\"], label = \"Train\", color = \"blue\", ax = ax[i])\n    sns.lineplot(history.history[\"val_loss\"], label = \"Validation\", color = \"orange\", ax = ax[i])\n    \n    #Set title for graph\n    ax[i].set_title(f\"Loss for Fold {i + 1} \", \n              fontsize = 15, \n              fontweight = 15)\n    #Set x_axis and y_axis label\n    ax[i].set_ylabel(\"Loss\")\n    ax[i].set_xlabel(\"Epochs\")\n\n#Display graph\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-24T13:47:02.390532Z","iopub.execute_input":"2024-06-24T13:47:02.390835Z","iopub.status.idle":"2024-06-24T13:47:04.346849Z","shell.execute_reply.started":"2024-06-24T13:47:02.390806Z","shell.execute_reply":"2024-06-24T13:47:04.345903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"background-color: #f5425a; font-family: Times New Roman; color: white; font-size: 150%; text-align: center; border-radius: 15px 15px; padding: 15px;\"><strong>SUBMISSION</strong></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: Times New Roman; color: black; font-size: 130%; text-align: left; border-radius: 15px 15px; padding: 15px;\"> Best results belongs to XGBOOST model, so I am gonna use it</p>","metadata":{}},{"cell_type":"code","source":"#define best_model\nbest_model = XGBClassifier(**params_XGB)\n#Define train and test set\nX_train = df_train.drop(\"Target\", axis = 1).copy()\ny_train = df_train[\"Target\"].copy()\nX_test = df_test.copy()\n\n#Fit model to train set\nbest_model.fit(X_train, y_train, eval_set = [(X_train, y_train)], verbose = 0)\n\n#Split the data to train and val set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n\n#Prediction on the val set\ny_pred_val = best_model.predict(X_val)\n\n#Accuracy_score for val set\nacc_val = accuracy_score(y_val, y_pred_val)\nprint(f\"Accuracy Score for Val Set: {acc_val}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:54:28.398343Z","iopub.execute_input":"2024-06-24T13:54:28.398718Z","iopub.status.idle":"2024-06-24T13:56:17.546845Z","shell.execute_reply.started":"2024-06-24T13:54:28.398687Z","shell.execute_reply":"2024-06-24T13:56:17.545981Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:56:23.473328Z","iopub.execute_input":"2024-06-24T13:56:23.473677Z","iopub.status.idle":"2024-06-24T13:56:23.483537Z","shell.execute_reply.started":"2024-06-24T13:56:23.473651Z","shell.execute_reply":"2024-06-24T13:56:23.482583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict on the test set\ny_pred_test = best_model.predict(X_test)\n#Change taret feature with predictions\ndf_sub[\"Target\"] = y_pred_test\n\ninverse_map = {\n    0:\"Graduate\",\n    1:\"Dropout\",\n    2:\"Enrolled\"\n           \n}\n#Ä°nverse map to Target feature\ndf_sub[\"Target\"] = df_sub[\"Target\"].map(inverse_map)\ndf_sub.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T13:56:32.069768Z","iopub.execute_input":"2024-06-24T13:56:32.070489Z","iopub.status.idle":"2024-06-24T13:56:36.60101Z","shell.execute_reply.started":"2024-06-24T13:56:32.07045Z","shell.execute_reply":"2024-06-24T13:56:36.6002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}